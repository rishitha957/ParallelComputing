{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79mEr7s7XkVi",
        "outputId": "79319e85-c1a1-447c-9aaa-c3fd24ed1b25"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\r\n",
        "%load_ext nvcc_plugin\r\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-b703hni1\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-b703hni1\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=a578709af172fdb514bd01dd0398eb8eeb1d313d6f64438c5cd1c2bab6ba946d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-su47zg5f/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re5N6RDiYUgZ"
      },
      "source": [
        "### 1 - Sum of elements in an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKCYPcWMZUXp",
        "outputId": "260cafc7-74ba-4eb3-ab4f-1331256fcd74"
      },
      "source": [
        "%%cu\r\n",
        "#include <bits/stdc++.h>\r\n",
        "\r\n",
        "#define outc(x) cout<<x<<\" \"\r\n",
        "#define outcn(x) cout<<x<<endl;\r\n",
        "#define out(x) cout<<#x \" - \"<<x<<\" \"\r\n",
        "#define outn(x) cout<<#x \" - \"<<x<<endl\r\n",
        "#define fl(i,n) for(int i=0;i<n;i++)\r\n",
        "\r\n",
        "using namespace std;\r\n",
        "using namespace std::chrono;\r\n",
        "\r\n",
        "\r\n",
        "__global__ void Arr_sum(int *c_a, int *c_n, int *c_sum){\r\n",
        "    int tid = threadIdx.x;\r\n",
        "    if(tid < (*c_n)){\r\n",
        "        atomicAdd(c_sum,c_a[tid]);\r\n",
        "    }\r\n",
        "}\r\n",
        "int main(){\r\n",
        "    ios_base::sync_with_stdio(0), cin.tie(0), cout.tie(0);\r\n",
        "    srand(chrono::high_resolution_clock::now().time_since_epoch().count());\r\n",
        "    int n = 15,sum=0;\r\n",
        "    int a[n];\r\n",
        "    int *c_a, *c_n, *c_sum;\r\n",
        "    fl(i,n){\r\n",
        "        a[i] = rand()%10;\r\n",
        "        outc(a[i]);\r\n",
        "    }\r\n",
        "    outcn(\"\");\r\n",
        "\r\n",
        "    cudaMalloc((void**)&c_a,n*sizeof(int));\r\n",
        "    cudaMalloc((void**)&c_n,sizeof(int));\r\n",
        "    cudaMalloc((void**)&c_sum,sizeof(int));\r\n",
        "\r\n",
        "    cudaMemcpy(c_a,a,n*sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(c_n,&n,sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(c_sum,&sum,sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    Arr_sum <<<1,n>>>(c_a,c_n,c_sum);\r\n",
        "\r\n",
        "    cudaMemcpy(&sum,c_sum,sizeof(int),cudaMemcpyDeviceToHost);\r\n",
        "    \r\n",
        "    outn(sum);\r\n",
        "    cudaFree(c_a);\r\n",
        "    cudaFree(c_n);\r\n",
        "    cudaFree(c_sum);\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 2 5 5 8 5 1 6 5 4 4 4 9 7 9 \n",
            "sum - 81\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQB1d_B3gb4h"
      },
      "source": [
        "### 2 - Sum of two arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-WfJyZIgixU",
        "outputId": "4282067b-a70c-4bc9-f6e0-52cfa18aa242"
      },
      "source": [
        "%%cu\r\n",
        "\r\n",
        "#include <bits/stdc++.h>\r\n",
        "\r\n",
        "#define outc(x) cout<<x<<\" \"\r\n",
        "#define outcn(x) cout<<x<<endl;\r\n",
        "#define out(x) cout<<#x \" - \"<<x<<\" \"\r\n",
        "#define outn(x) cout<<#x \" - \"<<x<<endl\r\n",
        "#define fl(i,n) for(int i=0;i<n;i++)\r\n",
        "\r\n",
        "using namespace std;\r\n",
        "using namespace std::chrono;\r\n",
        "\r\n",
        "const short N = 10;\r\n",
        "\r\n",
        "__global__ void Vector_Addition( const int *dev_a , const int *dev_b , int *dev_c)\r\n",
        "{\r\n",
        "      //Get the id of thread within a block\r\n",
        "      unsigned short tid = threadIdx.x ;\r\n",
        "     \r\n",
        "     // check the boundry condition for the threads\r\n",
        "      if ( tid < N ) \r\n",
        "            dev_c [tid] = dev_a[tid] + dev_b[tid] ;\r\n",
        "//printf(\"%p \\n\", &N);\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "int main ()\r\n",
        "{\r\n",
        "\r\n",
        "      int Host_a[N], Host_b[N], Host_c[N];\r\n",
        "\r\n",
        "      int *dev_a , *dev_b, *dev_c ;\r\n",
        "\r\n",
        "      cudaMalloc((void **)&dev_a , N*sizeof(int) ) ;\r\n",
        "      cudaMalloc((void **)&dev_b , N*sizeof(int) ) ;\r\n",
        "      cudaMalloc((void **)&dev_c , N*sizeof(int) ) ;\r\n",
        "\r\n",
        "      for ( int i = 0; i <N ; i++ )\r\n",
        "      {\r\n",
        "            Host_a[i] = rand()%10 ;\r\n",
        "            Host_b[i] = rand()%10 ; \r\n",
        "      }\r\n",
        "\r\n",
        "      cudaMemcpy (dev_a , Host_a , N*sizeof(int) , cudaMemcpyHostToDevice);\r\n",
        "      cudaMemcpy (dev_b , Host_b , N*sizeof(int) , cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "      Vector_Addition <<< 1, N  >>> (dev_a , dev_b , dev_c ) ;\r\n",
        "\r\n",
        "      cudaMemcpy(Host_c , dev_c , N*sizeof(int) , cudaMemcpyDeviceToHost);\r\n",
        "      outc(\"A Vector: \");\r\n",
        "      fl(i,N){\r\n",
        "          outc(Host_a[i]);\r\n",
        "      }\r\n",
        "      outcn(\"\");\r\n",
        "      outc(\"B Vector: \");\r\n",
        "      fl(i,N){\r\n",
        "          outc(Host_b[i]);\r\n",
        "      }\r\n",
        "      outcn(\"\");\r\n",
        "      outc(\"C Vector / sum : \");\r\n",
        "      fl(i,N){\r\n",
        "          outc(Host_c[i]);\r\n",
        "      }\r\n",
        "      outcn(\"\");\r\n",
        "      cudaFree (dev_a) ;\r\n",
        "      cudaFree (dev_b) ;\r\n",
        "      cudaFree (dev_c) ;\r\n",
        "      // printf(\"%p \\n\", &N);\r\n",
        "\r\n",
        "      return 0 ;\r\n",
        "\r\n",
        "}\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A Vector:  3 7 3 6 9 2 0 3 0 2 \n",
            "B Vector:  6 5 5 2 1 7 9 6 6 6 \n",
            "C Vector / sum :  9 12 8 8 10 9 9 9 6 8 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLNHJkMwiktE"
      },
      "source": [
        "### 3 - Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2YTJk01itP9",
        "outputId": "4ae981e7-3ba8-4c29-db24-020d57dcbe7b"
      },
      "source": [
        "%%cu\r\n",
        "\r\n",
        "#include <bits/stdc++.h>\r\n",
        "\r\n",
        "#define outc(x) cout<<x<<\" \"\r\n",
        "#define outcn(x) cout<<x<<endl;\r\n",
        "#define out(x) cout<<#x \" - \"<<x<<\" \"\r\n",
        "#define outn(x) cout<<#x \" - \"<<x<<endl\r\n",
        "#define fl(i,n) for(int i=0;i<n;i++)\r\n",
        "\r\n",
        "using namespace std;\r\n",
        "using namespace std::chrono;\r\n",
        "\r\n",
        "__global__ void Matrix_mul(int *a,int *b,int *c,int *m,int *n,int *p)\r\n",
        "{\r\n",
        "    int col=blockIdx.y*blockDim.y+threadIdx.y;\r\n",
        "    int row=blockIdx.x*blockDim.x+threadIdx.x;\r\n",
        "    int temp=0,i;\r\n",
        "\r\n",
        "    if(row<*m&&col<*p)\r\n",
        "    fl(i,*n){\r\n",
        "      temp+=a[row*(*n)+i]*b[i*(*p)+col];\r\n",
        "    }\r\n",
        "    c[row*(*p)+col]=temp;\r\n",
        "}\r\n",
        "\r\n",
        "int main()\r\n",
        "{\r\n",
        "    int m=rand()%5+1,n=rand()%5+1,p=rand()%5+1,i,j;\r\n",
        "    int a[m*n],b[n*p],c[m*n];\r\n",
        "    int *cuda_a,*cuda_b,*cuda_c,*cuda_m,*cuda_n,*cuda_p;\r\n",
        "    printf(\"Matrix A:\\n\");\r\n",
        "    for(i=0;i<m;i++)\r\n",
        "    {\r\n",
        "        for(j=0;j<n;j++)\r\n",
        "        {\r\n",
        "            a[i*n+j]=rand()%10;\r\n",
        "            printf(\"%d \",a[i*n+j]);       \r\n",
        "        }\r\n",
        "        printf(\"\\n\");\r\n",
        "    }\r\n",
        "    printf(\"\\nMatrix B:\\n\");\r\n",
        "    for(i=0;i<n;i++)\r\n",
        "    {\r\n",
        "        for(j=0;j<p;j++)\r\n",
        "        {\r\n",
        "            b[i*p+j]=rand()%10;\r\n",
        "            printf(\"%d \",b[i*p+j]);       \r\n",
        "        }\r\n",
        "        printf(\"\\n\");\r\n",
        "    }\r\n",
        "    printf(\"\\n\");\r\n",
        "\r\n",
        "    cudaMalloc((void**)&cuda_a,m*n*sizeof(int));\r\n",
        "    cudaMalloc((void**)&cuda_b,n*p*sizeof(int));\r\n",
        "    cudaMalloc((void**)&cuda_c,m*p*sizeof(int));\r\n",
        "    cudaMalloc((void**)&cuda_m,sizeof(int));\r\n",
        "    cudaMalloc((void**)&cuda_n,sizeof(int));\r\n",
        "    cudaMalloc((void**)&cuda_p,sizeof(int));\r\n",
        "\r\n",
        "    cudaMemcpy(cuda_a,a,m*n*sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(cuda_b,b,n*p*sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(cuda_m,&m,sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(cuda_n,&n,sizeof(int),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(cuda_p,&p,sizeof(int),cudaMemcpyHostToDevice);\r\n",
        " \r\n",
        "    dim3 threadsPerBlock(m,p);\r\n",
        "    dim3 blocksPerGrid(1,1);\r\n",
        "        \r\n",
        "\r\n",
        "    Matrix_mul<<<blocksPerGrid,threadsPerBlock>>> (cuda_a,cuda_b,cuda_c,cuda_m,cuda_n,cuda_p);   \r\n",
        "\r\n",
        "    cudaMemcpy(c,cuda_c,m*p*sizeof(int),cudaMemcpyDeviceToHost);\r\n",
        "    printf(\"Resultant Matrix:\\n\");\r\n",
        "    for(i=0;i<m;i++)\r\n",
        "    {\r\n",
        "        for(j=0;j<p;j++)\r\n",
        "        {\r\n",
        "            printf(\"%d \",c[i*p+j]);       \r\n",
        "        }\r\n",
        "        printf(\"\\n\");\r\n",
        "    }\r\n",
        "    cudaFree(cuda_a);\r\n",
        "    cudaFree(cuda_b);\r\n",
        "    cudaFree(cuda_c);\r\n",
        "    cudaFree(cuda_m);\r\n",
        "    cudaFree(cuda_n);\r\n",
        "    cudaFree(cuda_p);\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            "5 3 \n",
            "5 6 \n",
            "2 9 \n",
            "1 2 \n",
            "\n",
            "Matrix B:\n",
            "7 0 9 \n",
            "3 6 0 \n",
            "\n",
            "Resultant Matrix:\n",
            "44 18 45 \n",
            "53 36 45 \n",
            "41 54 18 \n",
            "13 12 9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwWnXKVwmB98"
      },
      "source": [
        "### 5 - BFS\r\n",
        "\r\n",
        "Adjacency matrix/list is replaced with compact adjacency list.\r\n",
        "\r\n",
        "V<sub>a</sub> -  Vertices of the graph\r\n",
        "\r\n",
        "H_Va [2i] will have start index in H_Ea, and H_V[2i+1] will have the length, \r\n",
        "(no.of outgoing edges)\r\n",
        "\r\n",
        "\r\n",
        "E<sub>a</sub> - Edge vertices for all the vertices in the graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7XrPuEBmJ-n"
      },
      "source": [
        "%%cu\r\n",
        "\r\n",
        "#include <bits/stdc++.h>\r\n",
        "\r\n",
        "using namespace std;\r\n",
        "using namespace std::chrono;\r\n",
        "\r\n",
        "#define outc(x) cout<<x<<\" \"\r\n",
        "#define outcn(x) cout<<x<<endl;\r\n",
        "#define out(x) cout<<#x \" - \"<<x<<\" \"\r\n",
        "#define outn(x) cout<<#x \" - \"<<x<<endl\r\n",
        "#define fl(i,n) for(int i=0;i<n;i++)\r\n",
        "#define outA(v,n) fl(i,n){outc(v[i]);}outcn(\"\");\r\n",
        "\r\n",
        "__global__ void CUDA_BFS_KERNEL(int *C_Va, int *C_Ea, int *C_Fa, int *C_Xa, \r\n",
        "                                int *C_Ca, int *n, int *n_e){\r\n",
        "                                    \r\n",
        "    int tid = threadIdx.x;\r\n",
        "\r\n",
        "    if(C_Fa[tid] == 1){\r\n",
        "        // outc(tid);\r\n",
        "        C_Fa[tid] = 0;\r\n",
        "        C_Xa[tid] = 1;\r\n",
        "        for(int i=C_Va[2*tid];i<C_Va[2*tid]+C_Va[(2*tid)+1];i++){\r\n",
        "            int nid = C_Ea[i];\r\n",
        "            if(C_Xa[nid] == 0){\r\n",
        "                C_Ca[nid] = C_Ca[tid]+1;\r\n",
        "                // # if __CUDA_ARCH__>=200\r\n",
        "                    //out(i);\r\n",
        "                    // outn(C_Ca[nid]);\r\n",
        "                // #endif  \r\n",
        "                C_Fa[nid] = 1;\r\n",
        "                // *flag = 0;\r\n",
        "            }\r\n",
        "        }\r\n",
        "    }                               \r\n",
        "}\r\n",
        "\r\n",
        "int main(){\r\n",
        "    ios_base::sync_with_stdio(0), cin.tie(0), cout.tie(0);\r\n",
        "    srand(chrono::high_resolution_clock::now().time_since_epoch().count());\r\n",
        "\r\n",
        "    int n = 5 + rand()%4;\r\n",
        "\r\n",
        "    int g[n][n];\r\n",
        "    outcn(\"Adj mat:\")\r\n",
        "    int n_e = 0;\r\n",
        "    fl(i,n){\r\n",
        "        fl(j,n){\r\n",
        "           if(i==j){\r\n",
        "               g[i][j] = 0;\r\n",
        "           } \r\n",
        "           else{\r\n",
        "               g[i][j] = rand()%2;\r\n",
        "           }\r\n",
        "           if(g[i][j]!=0){\r\n",
        "               n_e++;\r\n",
        "           }\r\n",
        "           outc(g[i][j]);\r\n",
        "        }\r\n",
        "        outcn(\"\");\r\n",
        "    }\r\n",
        "\r\n",
        "    int H_Va[n*2], H_Ea[n_e*2]; \r\n",
        "    // H_Va [2i] will have start index in H_Ea, and H_V[2i+1] will have the length, \r\n",
        "    //(no.of outgoing edges)\r\n",
        "    int length = 0;\r\n",
        "    fl(i,n){\r\n",
        "        int temp = length;\r\n",
        "        H_Va[i*2] = length;\r\n",
        "        fl(j,n){\r\n",
        "            if(g[i][j]!=0){\r\n",
        "                H_Ea[length] = j;\r\n",
        "                length++;\r\n",
        "            }\r\n",
        "        }\r\n",
        "        H_Va[(2*i)+1] = length - temp;\r\n",
        "    }\r\n",
        "\r\n",
        "    int H_Fa[n] = {0}, H_Xa[n] = {0}, H_Ca[n]; \r\n",
        "    fl(i,n){\r\n",
        "      H_Ca[i] = INT_MAX;\r\n",
        "      H_Fa[i] = 0;\r\n",
        "      H_Xa[i] = 0;\r\n",
        "    }\r\n",
        "    int s = rand()%n, flag = 0, *C_flag;\r\n",
        "    outn(s);\r\n",
        "    H_Ca[s] = 0;\r\n",
        "    H_Fa[s] = 1;\r\n",
        "\r\n",
        "    int *C_Va, *C_Ea, *C_Fa, *C_Xa, *C_Ca;\r\n",
        "    int sz = sizeof(int);\r\n",
        "    cudaMalloc((void**)&C_Va,2*n*sz);\r\n",
        "    cudaMemcpy(C_Va, H_Va, 2*sz*n, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_Ea,2*n_e*sz);\r\n",
        "    cudaMemcpy(C_Ea, H_Ea, 2*sz*n_e, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_Fa,n*sz);\r\n",
        "    cudaMemcpy(C_Fa, H_Fa, sz*n, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_Xa,n*sz);\r\n",
        "    cudaMemcpy(C_Xa, H_Xa, sz*n, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_Ca,n*sz);\r\n",
        "    cudaMemcpy(C_Ca, H_Ca, sz*n, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_flag,sz);\r\n",
        "    int *C_n, *C_ne;\r\n",
        "    cudaMalloc((void**)&C_n,sz);\r\n",
        "    cudaMemcpy(C_n, &n, sz, cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    cudaMalloc((void**)&C_ne,sz);\r\n",
        "    cudaMemcpy(C_ne, &n_e, sz, cudaMemcpyHostToDevice);\r\n",
        "    outcn(\"Va:\");\r\n",
        "    outA(H_Va,2*n);\r\n",
        "    outcn(\"Ea:\");\r\n",
        "    outA(H_Ea,H_Va[(2*n)-2]+H_Va[(2*n)-1]);\r\n",
        "    outcn(\"Ca:\");\r\n",
        "    outA(H_Ca,n);\r\n",
        "\r\n",
        "    while(1){\r\n",
        "        int flag = 0;\r\n",
        "        CUDA_BFS_KERNEL <<<1,n>>>(H_Va,H_Ea,H_Fa,H_Xa,H_Ca,C_n,C_ne);\r\n",
        "        cudaDeviceSynchronize();\r\n",
        "        cudaMemcpy(H_Fa, C_Fa, sz*n, cudaMemcpyDeviceToHost);\r\n",
        "\r\n",
        "        fl(i,n){\r\n",
        "            if(H_Fa[i]==1){\r\n",
        "                flag=1;\r\n",
        "                break;\r\n",
        "            }\r\n",
        "        }\r\n",
        "        if(flag==0){\r\n",
        "            break;\r\n",
        "        }\r\n",
        "        outcn(\"Cost:\");\r\n",
        "        outA(H_Ca,n);\r\n",
        "        outn(flag);\r\n",
        "\r\n",
        "    }\r\n",
        "    /* do{\r\n",
        "        flag = 0;\r\n",
        "        // cudaMemcpy(C_flag,&flag,sz,cudaMemcpyHostToDevice);\r\n",
        "        CUDA_BFS_KERNEL <<<1,n>>>(H_Va,H_Ea,H_Fa,H_Xa,H_Ca,C_n,C_ne);\r\n",
        "        cudaDeviceSynchronize();\r\n",
        "        // cudaMemcpy(&flag,C_flag,sz,cudaMemcpyDeviceToHost);\r\n",
        "       \r\n",
        "        cudaMemcpy(H_Fa, C_Fa, sz*n, cudaMemcpyDeviceToHost);\r\n",
        "        outcn(\"Fa:\");\r\n",
        "        outA(H_Fa,n);\r\n",
        "        fl(i,n){\r\n",
        "            if(H_Fa[i]==1){\r\n",
        "                flag=1;\r\n",
        "                break;\r\n",
        "            }\r\n",
        "        }\r\n",
        "        if(flag==0){\r\n",
        "            break;\r\n",
        "        }\r\n",
        "        outcn(\"Cost:\");\r\n",
        "        outA(H_Ca,n);\r\n",
        "        outn(flag);\r\n",
        "    }while(flag==0);*/\r\n",
        "\r\n",
        "    cudaMemcpy(H_Ca, C_Ca, sz*n, cudaMemcpyDeviceToHost);\r\n",
        "    \r\n",
        "    outcn(\"Cost:\");\r\n",
        "    outA(H_Ca,n);\r\n",
        "\r\n",
        "    cudaFree(C_Ea);\r\n",
        "    cudaFree(C_Va);\r\n",
        "    cudaFree(C_Ca);\r\n",
        "    cudaFree(C_Xa);\r\n",
        "    cudaFree(C_Fa);\r\n",
        "    cudaFree(C_flag);\r\n",
        "    cudaFree(C_n);\r\n",
        "    cudaFree(C_ne);\r\n",
        "\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_LXo5V7huO",
        "outputId": "b6398ca2-0429-420b-aa69-a42a614fe948"
      },
      "source": [
        "%%cu\r\n",
        "\r\n",
        "#include <bits/stdc++.h>\r\n",
        "\r\n",
        "#include <thrust/host_vector.h>\r\n",
        "#include <thrust/device_vector.h>\r\n",
        "#include <thrust/copy.h>\r\n",
        "#include <thrust/sort.h>\r\n",
        "\r\n",
        "#define outc(x) cout<<x<<\" \"\r\n",
        "#define outcn(x) cout<<x<<endl;\r\n",
        "#define out(x) cout<<#x \" - \"<<x<<\" \"\r\n",
        "#define outn(x) cout<<#x \" - \"<<x<<endl\r\n",
        "#define fl(i,n) for(int i=0;i<n;i++)\r\n",
        "#define outA(v,n) fl(i,n){outc(v[i]);}outcn(\"\");\r\n",
        "\r\n",
        "using namespace std;\r\n",
        "using namespace std::chrono;\r\n",
        "\r\n",
        "int main(void)\r\n",
        "{\r\n",
        "    ios_base::sync_with_stdio(0), cin.tie(0), cout.tie(0);\r\n",
        "    srand(chrono::high_resolution_clock::now().time_since_epoch().count());\r\n",
        " \r\n",
        "    thrust::host_vector<int> h(10);\r\n",
        "    fl(i,10){\r\n",
        "        h[i] = rand()%10;\r\n",
        "    }\r\n",
        "    thrust::device_vector<int> d = h;\r\n",
        "    thrust::sort(d.begin(),d.end());\r\n",
        "    \r\n",
        "    fl(i,10){\r\n",
        "        outc(d[i]);\r\n",
        "    }\r\n",
        "    outcn(\"\");\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2 3 4 5 5 5 6 9 9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}